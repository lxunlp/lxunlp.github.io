---
title: "Work on Multi-Modal"
date: 2022-03-20
categories:
  - Blog
tags:
  - NLP
  - multi-modal

---

**Unifying Vision-and-Language Tasks via Text Generation**. Cho et al. ICML'21\
<https://arxiv.org/abs/2102.02779>

**SIMVLM: SIMPLE VISUAL LANGUAGE MODEL PRETRAINING WITH WEAK SUPERVISION**. Wang et al. ICLR'22\
Visual Language Model (VLM) pretraining for generative tasks.\
BART style pretraining, with raw image patches prepended in the sequence to be conditioned;
image-text pair can be large-scale noisy web data.\
<https://arxiv.org/pdf/2108.10904>

**Clinical-BERT: Vision-Language Pre-Training for Radiograph Diagnosis and Reports Generation**. Yan and Pei. AAAI'22\
<https://aaai-2022.virtualchair.net/poster_aaai4013>